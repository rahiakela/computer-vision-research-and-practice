{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPPvz4p/0WUHqQ+t295lxXA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/computer-vision-research-and-practice/blob/main/hands-on-computer-vision-with-detectron2/04-custom-object-detection/01_data_processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Processing"
      ],
      "metadata": {
        "id": "X4aqooRa0WwP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset used is the brain tumor object detection dataset available from [Kaggle](https://www.kaggle.com/datasets/davidbroberts/brain-tumor-object-detectiondatasets).\n",
        "\n",
        "This dataset is chosen because medical image processing is a critical subfield in computer vision. At the same\n",
        "time, the task is challenging, and the number of images is appropriate for demonstration purposes.\n",
        "\n"
      ],
      "metadata": {
        "id": "ENJEZSze0n3b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "Ws6uMtirxsL4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install \"git+https://github.com/facebookresearch/detectron2.git\"\n",
        "!sudo apt-get install tree\n",
        "!pip install -q pylabel"
      ],
      "metadata": {
        "id": "XvSM45Nvxsc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import detectron2\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "\n",
        "import os\n",
        "from glob import glob\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "import yaml\n",
        "from yaml.loader import SafeLoader\n",
        "from pylabel import importer\n",
        "\n",
        "import torch\n",
        "import cv2\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Suppress some user warnings\n",
        "import warnings\n",
        "warnings.simplefilter(action='ignore', category=UserWarning)"
      ],
      "metadata": {
        "id": "fVtmSc7Cyjra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(detectron2.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oI7nUOMpyQqA",
        "outputId": "bb363ead-9b1a-4687-d2eb-6aa97daf526a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/PacktPublishing/Hands-On-Computer-Vision-with-Detectron2/blob/main/datasets/braintumors.zip?raw=true -O braintumors.zip\n",
        "!unzip braintumors.zip -d braintumors"
      ],
      "metadata": {
        "id": "vu_gkcKR_cpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dataset"
      ],
      "metadata": {
        "id": "c-HtucAUy9JU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_folder = \"braintumors\"\n",
        "data_folder_yolo = data_folder + \"_yolo\"\n",
        "data_folder_coco = data_folder + \"_coco\"\n",
        "\n",
        "folders = os.listdir(\"braintumors\")\n",
        "print(folders)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Af-r9SR2y_g5",
        "outputId": "7374bce2-74c5-4043-c6c5-cf2b0e7c0ce9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['coronal_t1wce_2_class', 'sagittal_t1wce_2_class', 'axial_t1wce_2_class']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!tree braintumors/ -d"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqC0kIGCMiS3",
        "outputId": "67fcf9b3-81d0-4e79-87d3-3828f22efefe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[01;34mbraintumors/\u001b[0m\n",
            "├── \u001b[01;34maxial_t1wce_2_class\u001b[0m\n",
            "│   ├── \u001b[01;34mimages\u001b[0m\n",
            "│   │   ├── \u001b[01;34mtest\u001b[0m\n",
            "│   │   └── \u001b[01;34mtrain\u001b[0m\n",
            "│   └── \u001b[01;34mlabels\u001b[0m\n",
            "│       ├── \u001b[01;34mtest\u001b[0m\n",
            "│       └── \u001b[01;34mtrain\u001b[0m\n",
            "├── \u001b[01;34mcoronal_t1wce_2_class\u001b[0m\n",
            "│   ├── \u001b[01;34mimages\u001b[0m\n",
            "│   │   ├── \u001b[01;34mtest\u001b[0m\n",
            "│   │   └── \u001b[01;34mtrain\u001b[0m\n",
            "│   └── \u001b[01;34mlabels\u001b[0m\n",
            "│       ├── \u001b[01;34mtest\u001b[0m\n",
            "│       └── \u001b[01;34mtrain\u001b[0m\n",
            "└── \u001b[01;34msagittal_t1wce_2_class\u001b[0m\n",
            "    ├── \u001b[01;34mimages\u001b[0m\n",
            "    │   ├── \u001b[01;34mtest\u001b[0m\n",
            "    │   └── \u001b[01;34mtrain\u001b[0m\n",
            "    └── \u001b[01;34mlabels\u001b[0m\n",
            "        ├── \u001b[01;34mtest\u001b[0m\n",
            "        └── \u001b[01;34mtrain\u001b[0m\n",
            "\n",
            "21 directories\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's count the number of images and labels from a dataset with the YOLO annotation format\n"
      ],
      "metadata": {
        "id": "FR3bC-H9N8k6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Input image"
      ],
      "metadata": {
        "id": "iWtpY4zb1uZ-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img = cv2.imread(\"input.jpeg\")\n",
        "height, width = img.shape[:2]\n",
        "image = torch.as_tensor(img.astype(\"float32\").transpose(2, 0, 1))"
      ],
      "metadata": {
        "id": "LP4NNFEB1vDY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5lbFmqtwmgu",
        "outputId": "d61fef1d-ecd7-4725-aeca-26a9208aa820"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[199., 199., 199.,  ..., 203., 203., 203.],\n",
              "         [199., 199., 199.,  ..., 203., 203., 203.],\n",
              "         [199., 199., 199.,  ..., 204., 204., 204.],\n",
              "         ...,\n",
              "         [ 73.,  90.,  91.,  ...,  95.,  92.,  91.],\n",
              "         [ 87.,  88.,  86.,  ...,  92.,  93.,  93.],\n",
              "         [ 81.,  78.,  84.,  ...,  83.,  89.,  90.]],\n",
              "\n",
              "        [[147., 147., 147.,  ..., 144., 144., 144.],\n",
              "         [147., 147., 147.,  ..., 144., 144., 144.],\n",
              "         [147., 147., 147.,  ..., 145., 145., 145.],\n",
              "         ...,\n",
              "         [114., 131., 133.,  ..., 137., 134., 133.],\n",
              "         [131., 132., 130.,  ..., 133., 134., 134.],\n",
              "         [125., 122., 128.,  ..., 124., 127., 128.]],\n",
              "\n",
              "        [[106., 106., 106.,  ..., 104., 104., 104.],\n",
              "         [106., 106., 106.,  ..., 104., 104., 104.],\n",
              "         [106., 106., 106.,  ..., 105., 105., 105.],\n",
              "         ...,\n",
              "         [206., 223., 222.,  ..., 233., 230., 229.],\n",
              "         [222., 223., 221.,  ..., 226., 227., 227.],\n",
              "         [216., 213., 219.,  ..., 217., 221., 222.]]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}