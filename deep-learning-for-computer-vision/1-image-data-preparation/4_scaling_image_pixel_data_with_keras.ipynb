{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4-scaling-image-pixel-data-with-keras.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNCP9aojJwM6yC0+YYjskK3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/deep-learning-for-computer-vision/blob/main/1-image-data-preparation/4_scaling_image_pixel_data_with_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU2gNshCysb0"
      },
      "source": [
        "## Scaling Image Pixel Data with Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "op9sngvIy52s"
      },
      "source": [
        "The pixel values in images must be scaled prior to providing the images as input to a deep learning neural network model during the training or evaluation of the model. Traditionally, the images would have to be scaled prior to the development of the model and stored in memory or on disk in the scaled format.\n",
        "\n",
        "An alternative approach is to scale the images using a preferred scaling technique just-in-time during the training or model evaluation process. Keras supports this type of data preparation for image data via the **ImageDataGenerator** class and API."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eUan44GH26H"
      },
      "source": [
        "##Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfUckPrgH4pm"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.datasets import mnist"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ur8TElwMzTT3"
      },
      "source": [
        "## Load MNIST dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_Kfs9shzt1u"
      },
      "source": [
        "Before we dive into the usage of the ImageDataGenerator class for preparing image data, we must select an image dataset on which to test the generator. The MNIST problem, is an image classification problem comprised of 70,000 images of handwritten digits. The goal of the problem is to classify a given image of a handwritten digit as an integer from 0 to 9. As such, it is a multiclass image classification problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oY_VEuVbz6Gt",
        "outputId": "ad52c28c-3991-446c-f7eb-acb2d4d34dd6"
      },
      "source": [
        "# loading the MNIST dataset\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "# summarize dataset shape\n",
        "print(\"Train: \", x_train.shape, y_train.shape)\n",
        "print(\"Test: \", x_test.shape, y_test.shape)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "Train:  (60000, 28, 28) (60000,)\n",
            "Test:  (10000, 28, 28) (10000,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIRYfwTE0Lvn",
        "outputId": "28928fcb-717f-402d-af83-7d4748934540"
      },
      "source": [
        "# summarize pixel values\n",
        "print(\"Train: \", x_train.min(), x_train.max(), x_train.mean(), x_train.std())\n",
        "print(\"Test: \", x_test.min(), x_test.max(), x_test.mean(), x_test.std())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train:  0 255 33.318421449829934 78.56748998339798\n",
            "Test:  0 255 33.791224489795916 79.17246322228644\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2pL5i_Dz5ZK"
      },
      "source": [
        "## Image Pixel Scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVxn8tkm0mBo"
      },
      "source": [
        "The ImageDataGenerator class in Keras provides a suite of techniques for scaling pixel values in your image dataset prior to modeling. The class will wrap your image dataset, then when requested, it will return images in batches to the algorithm during training, validation, or evaluation and apply the scaling operations just-in-time. This provides an efficient and convenient approach to scaling image data when modeling with neural networks.\n",
        "\n",
        "The three main types of pixel scaling techniques supported by the ImageDataGenerator class are as follows:\n",
        "\n",
        "- **Pixel Normalization**: scale pixel values to the range 0-1.\n",
        "- **Pixel Centering**: scale pixel values to have a zero mean.\n",
        "- **Pixel Standardization**: scale pixel values to have a zero mean and unit variance.\n",
        "\n",
        "Pixel standardization is supported at two levels: either per-image (called sample-wise) or per-dataset (called feature-wise). Specifically, just the mean, or the mean and standard deviation statistics required to standardize pixel values can be calculated from the pixel values in each image only (sample-wise) or across the entire training dataset (feature-wise)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AYPFqHFMD3K"
      },
      "source": [
        "## Normalizing Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwjMQtdMMRKt"
      },
      "source": [
        "The ImageDataGenerator class can be used to rescale pixel values from the range of `0-255` to the range `0-1` preferred for neural network models. Scaling data to the range of `0-1` is traditionally referred to as normalization. This can be achieved by setting the rescale argument to a ratio by which each pixel can be multiplied to achieve the desired range. In this case, the ratio is $\\frac{1}{255}$ or about `0.0039`.\n",
        "\n",
        "The ImageDataGenerator does not need to be fit in this case because there are no global statistics line mean and standard deviation that need to be calculated. Next, iterators can be created using the generator for both the train and test datasets. We will use a batch size of `64`. This means that each of the train and test datasets of images are divided into groups of `64` images that will then be scaled when returned from the iterator.\n",
        "\n",
        "We can then confirm that the pixel normalization has been performed as expected by retrieving the first batch of scaled images and inspecting the min and max pixel values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGvYe-wE08up",
        "outputId": "1172c83b-9872-4ebe-8461-a53295dea6db"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# reshape dataset to have a single channel\n",
        "width, height, channels = x_train.shape[1], x_train.shape[2], 1\n",
        "x_train = x_train.reshape((x_train.shape[0], width, height, channels))\n",
        "x_test = x_test.reshape((x_test.shape[0], width, height, channels))\n",
        "\n",
        "# confirm scale of pixels\n",
        "print(\"Train min=%.3f, max=%.3f\" % (x_train.min(), x_train.max()))\n",
        "print(\"Test min=%.3f, max=%.3f\" % (x_test.min(), x_test.max()))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train min=0.000, max=255.000\n",
            "Test min=0.000, max=255.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MeHZIVrNOMeu",
        "outputId": "35b9e13d-80de-4fd3-a13f-49e18c143f2f"
      },
      "source": [
        "# create generator (1.0/255.0 = 0.003921568627451)\n",
        "datagen = ImageDataGenerator(rescale=1.0 / 255.0)\n",
        "\n",
        "##########Note: there is no need to fit the generator in this case##########\n",
        "# prepare a iterators to scale images\n",
        "train_iterator = datagen.flow(x_train, y_train, batch_size=64)\n",
        "test_iterator = datagen.flow(x_test, y_test, batch_size=64)\n",
        "print(\"Batches train=%d, test=%d\" % (len(train_iterator), len(test_iterator)))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batches train=938, test=157\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A5M01SGhQOY6",
        "outputId": "57e68d33-ed6b-4ad1-d8a3-7edb488d61ba"
      },
      "source": [
        "# confirm the scaling works\n",
        "batch_x, batch_y = train_iterator.next()\n",
        "print(\"Batch shape=%s, min=%.3f, max=%.3f\" % (batch_x.shape, batch_x.min(), batch_x.max()))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Batch shape=(64, 28, 28, 1), min=0.000, max=1.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIov82uUQuJa"
      },
      "source": [
        "The ImageDataGenerator does not need to be fit on the training dataset as there is nothing that needs to be calculated, we have provided the scale factor directly. A single batch of normalized images is retrieved and we can confirm that the min and max pixel values are zero and one respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IeyCGGQ21zvT"
      },
      "source": [
        "##Centering Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JE4ostO1118"
      },
      "source": [
        "Another popular pixel scaling method is to calculate the mean pixel value across the entire training dataset, then subtract it from each image. This is called centering and has the effect of centering the distribution of pixel values on zero: that is, the mean pixel value for centered images will be zero. \n",
        "\n",
        "The ImageDataGenerator class refers to centering that uses the mean calculated on the training dataset as feature-wise centering. It requires that the statistic is calculated on the training dataset prior to scaling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Cz4gYMG1jG_",
        "outputId": "45613ab8-e9d6-461e-a774-51bdb34c9968"
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# reshape dataset to have a single channel\n",
        "width, height, channels = x_train.shape[1], x_train.shape[2], 1\n",
        "x_train = x_train.reshape((x_train.shape[0], width, height, channels))\n",
        "x_test = x_test.reshape((x_test.shape[0], width, height, channels))\n",
        "\n",
        "# confirm scale of pixels\n",
        "print(\"Mean train=%.3f, test=%.3f\" % (x_train.mean(), x_test.mean()))\n",
        "\n",
        "# create generator that centers pixel values\n",
        "datagen = ImageDataGenerator(featurewise_center=True)\n",
        "# calculate the mean on the training dataset\n",
        "datagen.fit(x_train)\n",
        "print(\"Data Generator Mean:%.3f\" % datagen.mean)\n",
        "\n",
        "# demonstrate effect on a single batch of samples\n",
        "iterator = datagen.flow(x_train, y_train, batch_size=64)\n",
        "# get a batch\n",
        "x_batch, y_batch = iterator.next()\n",
        "# mean pixel value in the batch\n",
        "print(x_batch.shape, x_batch.mean())\n",
        "\n",
        "# demonstrate effect on entire training dataset\n",
        "iterator = datagen.flow(x_train, y_train, batch_size=len(x_train), shuffle=False)\n",
        "# get a batch\n",
        "x_batch, y_batch = iterator.next()\n",
        "# mean pixel value in the batch\n",
        "print(x_batch.shape, x_batch.mean())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mean train=33.318, test=33.791\n",
            "Data Generator Mean:33.318\n",
            "(64, 28, 28, 1) 0.2942951\n",
            "(60000, 28, 28, 1) -1.9512918e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RFc8KZ1yJPrX"
      },
      "source": [
        "The ImageDataGenerator is fit on the training dataset and we can confirm that the mean pixel value matches our own manual calculation. A single batch of centered images is retrieved and we can confirm that the mean pixel value is a small-ish value close to zero. The test is repeated using the entire training dataset as the batch size, and in this case, the mean pixel value for the\n",
        "scaled dataset is a number very close to zero, confirming that centering is having the desired effect."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEZIKrZgJT71"
      },
      "source": [
        "##Standardizing Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZT9KF9SJY5F"
      },
      "source": [
        "Standardization is a data scaling technique that assumes that the distribution of the data is Gaussian and shifts the distribution of the data to have a mean of zero and a standard deviation of one. Data with this distribution is referred to as a standard Gaussian. It can be beneficial when training neural networks as the dataset sums to zero and the inputs are small values in\n",
        "the rough range of about -3.0 to 3.0 (e.g. 99.7 of the values will fall within three standard deviations of the mean). \n",
        "\n",
        "Standardization of images is achieved by subtracting the mean pixel value and dividing the result by the standard deviation of the pixel values. The mean and\n",
        "standard deviation statistics can be calculated on the training dataset, Keras refers to this as feature-wise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnntNR0yKC5J",
        "outputId": "973fe1c9-c76b-49b0-f10c-785397045ab3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "# reshape dataset to have a single channel\n",
        "width, height, channels = x_train.shape[1], x_train.shape[2], 1\n",
        "x_train = x_train.reshape((x_train.shape[0], width, height, channels))\n",
        "x_test = x_test.reshape((x_test.shape[0], width, height, channels))\n",
        "\n",
        "# report pixel means and standard deviations\n",
        "print(\"Statistics train=%.3f (%.3f), test=%.3f (%.3f)\" % (x_train.mean(), x_train.std(), x_test.mean(), x_test.std()))\n",
        "\n",
        "# create generator that centers pixel values\n",
        "datagen = ImageDataGenerator(featurewise_center=True, featurewise_std_normalization=True)\n",
        "# calculate the mean on the training dataset\n",
        "datagen.fit(x_train)\n",
        "print(\"Data Generator Mean:%.3f, std=%.3f\" % (datagen.mean, datagen.std))\n",
        "\n",
        "# demonstrate effect on a single batch of samples\n",
        "iterator = datagen.flow(x_train, y_train, batch_size=64)\n",
        "# get a batch\n",
        "x_batch, y_batch = iterator.next()\n",
        "# mean pixel value in the batch\n",
        "print(x_batch.shape, x_batch.mean(), x_batch.std())\n",
        "\n",
        "# demonstrate effect on entire training dataset\n",
        "iterator = datagen.flow(x_train, y_train, batch_size=len(x_train), shuffle=False)\n",
        "# get a batch\n",
        "x_batch, y_batch = iterator.next()\n",
        "# mean pixel value in the batch\n",
        "print(x_batch.shape, x_batch.mean(), x_batch.std())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Statistics train=33.318 (78.567), test=33.791 (79.172)\n",
            "Data Generator Mean:33.318, std=78.567\n",
            "(64, 28, 28, 1) -0.010537894 0.98354304\n",
            "(60000, 28, 28, 1) -3.4560264e-07 0.9999998\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}