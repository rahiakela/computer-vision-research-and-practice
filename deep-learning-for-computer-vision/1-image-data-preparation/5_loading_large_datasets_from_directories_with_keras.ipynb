{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "5-loading-large-datasets-from-directories-with-keras.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMN+BN08RipMBrtGbsY3tv3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/deep-learning-for-computer-vision/blob/main/1-image-data-preparation/5_loading_large_datasets_from_directories_with_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zU2gNshCysb0"
      },
      "source": [
        "## Loading Large Datasets From Directories with Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "op9sngvIy52s"
      },
      "source": [
        "There are conventions for storing and structuring your image dataset on disk in order to make it fast and efficient to load and when training and evaluating deep learning models. Once structured, you can use tools like the **ImageDataGenerator** class in the Keras deep learning library to automatically load your train, test, and validation datasets. In addition, the generator will progressively load the images in your dataset (e.g. just-in-time), allowing you to work with both small and very large datasets containing thousands or millions of images that may not fit into system memory. In this tutorial, you will discover how to structure an image dataset and\n",
        "how to load it progressively when fitting and evaluating a deep learning model.\n",
        "\n",
        "This is divided into three parts; they are:\n",
        "\n",
        "1. Dataset Directory Structure\n",
        "2. Example Dataset Structure\n",
        "3. How to Progressively Load Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eUan44GH26H"
      },
      "source": [
        "##Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfUckPrgH4pm"
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iCHertS8K9hP",
        "outputId": "34d34b59-3433-4b77-f899-7ca9184ec9a4"
      },
      "source": [
        "%%shell\n",
        "\n",
        "wget -q https://machinelearningmastery.com/wp-content/uploads/2019/01/red_car_01.jpg\n",
        "wget -q https://machinelearningmastery.com/wp-content/uploads/2019/01/blue_car_01.jpg\n",
        "\n",
        "# making directory structure\n",
        "mkdir data\n",
        "mkdir data/train\n",
        "mkdir data/test\n",
        "mkdir data/validation\n",
        "\n",
        "mkdir data/train/red\n",
        "mkdir data/train/blue\n",
        "mkdir data/test/red\n",
        "mkdir data/test/blue\n",
        "mkdir data/validation/red\n",
        "mkdir data/validation/blue\n",
        "\n",
        "# copy image to directory structure\n",
        "cp -r red_car_01.jpg data/train/red/\n",
        "cp -r blue_car_01.jpg data/train/blue/\n",
        "\n",
        "cp -r red_car_01.jpg data/test/red/\n",
        "cp -r blue_car_01.jpg data/test/blue/\n",
        "\n",
        "cp -r red_car_01.jpg data/validation/red/\n",
        "cp -r blue_car_01.jpg data/validation/blue/"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2pL5i_Dz5ZK"
      },
      "source": [
        "## Progressively Load Images"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVxn8tkm0mBo"
      },
      "source": [
        "Instead of loading all images into memory, it will load just enough images into memory for the current and perhaps the next few mini-batches when training and evaluating a deep learning model. I refer to this as progressive loading (or lazy loading), as the dataset is progressively loaded from file, retrieving just enough data for what is needed immediately.\n",
        "\n",
        "Two additional benefits of the using the ImageDataGenerator class is that it can also automatically scale pixel values of images and it can automatically generate augmented versions of images.\n",
        "\n",
        "The pattern for using the ImageDataGenerator class is used as follows:\n",
        "\n",
        "- Construct and configure an instance of the ImageDataGenerator class.\n",
        "- Retrieve an iterator by calling the flow from directory() function.\n",
        "- Use the iterator in the training or evaluation of a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A92Or-e2MgE_",
        "outputId": "86266ebc-fca6-492a-e98e-1319db7fd766"
      },
      "source": [
        "# create generator\n",
        "datagen = ImageDataGenerator()\n",
        "\n",
        "# prepare an iterators for each dataset\n",
        "train_itr = datagen.flow_from_directory(\"data/train/\", class_mode=\"binary\")\n",
        "val_itr = datagen.flow_from_directory(\"data/validation/\", class_mode=\"binary\")\n",
        "test_itr = datagen.flow_from_directory(\"data/test/\", class_mode=\"binary\")\n",
        "\n",
        "# confirm the iterator works\n",
        "batch_x, batch_y = train_itr.next()\n",
        "\n",
        "print(\"Batch shape=%s, min=%.3f, max=%.3f\" % (batch_x.shape, batch_x.min(), batch_x.max()))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 2 images belonging to 2 classes.\n",
            "Found 2 images belonging to 2 classes.\n",
            "Found 2 images belonging to 2 classes.\n",
            "Batch shape=(2, 256, 256, 3), min=0.000, max=255.000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ha6dLETmN5EV"
      },
      "source": [
        "Reference:\n",
        "\n",
        "https://keras.io/api/preprocessing/image/\n",
        "\n",
        "https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html"
      ]
    }
  ]
}