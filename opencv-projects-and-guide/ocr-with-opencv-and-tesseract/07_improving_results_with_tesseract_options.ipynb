{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "07-improving-results-with-tesseract-options.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPnwxqW2b6iHFRNnulaMJzA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/computer-vision-research-and-practice/blob/main/opencv-projects-and-guide/ocr-with-opencv-and-tesseract/07_improving_results_with_tesseract_options.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Improving OCR Results with Tesseract Options"
      ],
      "metadata": {
        "id": "Si_AnbHH8t4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "sudo apt install tesseract-ocr\n",
        "pip install tesseract\n",
        "pip install pytesseract\n",
        "pip install Pillow==9.0.0"
      ],
      "metadata": {
        "id": "CTdT0BiA8mNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Just restart the colab environment."
      ],
      "metadata": {
        "id": "Dy5I4iPZASXI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import pytesseract\n",
        "import csv\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "4T18ensl8pDG"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pytesseract.pytesseract.tesseract_cmd = (r'/usr/bin/tesseract')"
      ],
      "metadata": {
        "id": "6QMeK_4a-J6b"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's download images."
      ],
      "metadata": {
        "id": "UR6-6OuaE9pV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "wget https://github.com/rahiakela/computer-vision-research-and-practice/raw/main/opencv-projects-and-guide/ocr-with-opencv-and-tesseract/images/text-orient-1.png\n",
        "wget https://github.com/rahiakela/computer-vision-research-and-practice/raw/main/opencv-projects-and-guide/ocr-with-opencv-and-tesseract/images/text-orient-1.png"
      ],
      "metadata": {
        "id": "86MrGO6AFCFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!tesseract --help-psm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_q7pgCjcEAj",
        "outputId": "003563dc-f239-4f55-8a38-8dc5f2da94ea"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page segmentation modes:\n",
            "  0    Orientation and script detection (OSD) only.\n",
            "  1    Automatic page segmentation with OSD.\n",
            "  2    Automatic page segmentation, but no OSD, or OCR.\n",
            "  3    Fully automatic page segmentation, but no OSD. (Default)\n",
            "  4    Assume a single column of text of variable sizes.\n",
            "  5    Assume a single uniform block of vertically aligned text.\n",
            "  6    Assume a single uniform block of text.\n",
            "  7    Treat the image as a single text line.\n",
            "  8    Treat the image as a single word.\n",
            "  9    Treat the image as a single word in a circle.\n",
            " 10    Treat the image as a single character.\n",
            " 11    Sparse text. Find as much text as possible in no particular order.\n",
            " 12    Sparse text with OSD.\n",
            " 13    Raw line. Treat the image as a single text line,\n",
            "       bypassing hacks that are Tesseract-specific.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PSM 0"
      ],
      "metadata": {
        "id": "WEqc2xwTFWjN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Orientation and script detection (OSD) examines the input image, but instead of returning the\n",
        "actual OCR’d text, OSD returns two values:\n",
        "\n",
        "* How the page is oriented, in degrees\n",
        "* The confidence of the script"
      ],
      "metadata": {
        "id": "LHVUg6zCUauM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_orientation(img_path, options):\n",
        "  image = cv2.imread(img_path)\n",
        "\n",
        "  image_bgr = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  # determine the text orientation\n",
        "  results = pytesseract.image_to_osd(image_bgr, output_type=pytesseract.Output.DICT, config=options)\n",
        "\n",
        "  print(f\"Page number: {results['page_num']}\")\n",
        "  print(f\"Orientation: {results['orientation']}\")\n",
        "  print(f\"Rotate: {results['rotate']}\")\n",
        "  print(f\"Orientation confidence: {results['orientation_conf']}\")\n",
        "  print(f\"Script: {results['script']}\")\n",
        "  print(f\"Script confidence: {results['script_conf']}\")"
      ],
      "metadata": {
        "id": "WPbQHkMKhNL6"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_orientation(\"text-orient-1.png\", options=\"--psm 0\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6WfLOFed9NIV",
        "outputId": "54efd284-48e7-4344-a738-df56e03c3332"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page number: 0\n",
            "Orientation: 0\n",
            "Rotate: 0\n",
            "Orientation confidence: 4.51\n",
            "Script: Latin\n",
            "Script confidence: 4.58\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text_orientation(\"text-orient-2.png\", options=\"--psm 0\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_t-m5UZh_GaH",
        "outputId": "df1ca7a8-3bed-4314-d471-e1c7f5c63787"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page number: 0\n",
            "Orientation: 90\n",
            "Rotate: 270\n",
            "Orientation confidence: 3.7\n",
            "Script: Latin\n",
            "Script confidence: 8.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PSM 1"
      ],
      "metadata": {
        "id": "P6m2K9dMamiB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def psm_options(img_path, options=None):\n",
        "  image = cv2.imread(img_path)\n",
        "\n",
        "  image_bgr = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "  # determine the text orientation\n",
        "  results = pytesseract.image_to_string(image_bgr, config=options)\n",
        "  return results"
      ],
      "metadata": {
        "id": "GxIC2bgla0pk"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = psm_options(\"text-orient-1.png\", options=\"--psm 1\")\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "iNP_YDBuAxiX",
        "outputId": "38fbc979-53f9-486c-8e7e-190543c96884"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"In the first part of this tutorial, we'll discuss how\\nautoencoders can be used used for image retrieval\\nand building image search engines.\\n\\nFrom there, we'll implement a convolutional autoencoder\\nthat we'll then train on our image dataset.\\n\\x0c\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = psm_options(\"text-orient-2.png\", options=\"--psm 1\")\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "3mlWQsuyA2fj",
        "outputId": "72280464-8ab2-41e3-8edb-1cfb200e1794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" \\n\\nIn the first part of this tutorial, we'll discuss how\\nautoencoders can be used used for image retrieval\\nand building image search engines.\\n\\nFrom there, we'll implement a convolutional autoencoder\\nthat we'll then train on our image dataset.\\n\\x0c\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PSM 3"
      ],
      "metadata": {
        "id": "3-nX5M04cJzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = psm_options(\"text-orient-1.png\", options=\"--psm 3\")\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "xzK1Bw-ucLF1",
        "outputId": "81ae4ef4-3ad4-42e5-fa81-15a53326e6b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"In the first part of this tutorial, we'll discuss how\\nautoencoders can be used used for image retrieval\\nand building image search engines.\\n\\nFrom there, we'll implement a convolutional autoencoder\\nthat we'll then train on our image dataset.\\n\\x0c\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = psm_options(\"text-orient-2.png\", options=\"--psm 3\")\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "I2CuUU-zcQBw",
        "outputId": "13419e85-a926-49f7-8673-ab6f17e03609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" \\n\\nIn the first part of this tutorial, we'll discuss how\\nautoencoders can be used used for image retrieval\\nand building image search engines.\\n\\nFrom there, we'll implement a convolutional autoencoder\\nthat we'll then train on our image dataset.\\n\\x0c\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PSM 3 is the default behavior of Tesseract."
      ],
      "metadata": {
        "id": "htk_TDOgcbLv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = psm_options(\"text-orient-1.png\")\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "SDqueZIucZ-c",
        "outputId": "0ea4f1ec-6fb5-4c68-bb4b-cf71916274cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"In the first part of this tutorial, we'll discuss how\\nautoencoders can be used used for image retrieval\\nand building image search engines.\\n\\nFrom there, we'll implement a convolutional autoencoder\\nthat we'll then train on our image dataset.\\n\\x0c\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = psm_options(\"text-orient-2.png\")\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "id": "aOZjU9uAcj9e",
        "outputId": "53e652ca-e4d7-4f3b-edf2-a339409edfe4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" \\n\\nIn the first part of this tutorial, we'll discuss how\\nautoencoders can be used used for image retrieval\\nand building image search engines.\\n\\nFrom there, we'll implement a convolutional autoencoder\\nthat we'll then train on our image dataset.\\n\\x0c\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PSM 4"
      ],
      "metadata": {
        "id": "B_FD1yEydSfY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = psm_options(\"whole_foods-2.png\")\n",
        "results"
      ],
      "metadata": {
        "id": "5EQivC2rdUFZ",
        "outputId": "e769ee67-76b2-41b7-eb98-fc0df674e3e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'WHOLE\\nFOODS\\n[Mm AR K E T)\\n\\nWHOLE FOODS MARKET - WESTPORT,CT 06880\\n399 POST RD WEST ~ (203) 227-6858\\n\\n365\\n365\\n366\\n365\\n\\nee\\n\\nwee TAX\\n\\nBACON LS\\nBACON LS\\nBACON LS\\nBACON LS\\nBROTH CHIC\\n\\nFLOUR ALMOND\\n\\nCHKN BRST BNLSS SK\\n\\nHEAVY CREAM\\n\\nBALSMC REDUCT\\n\\nBEEF GRND 85/1§\\n\\nJUICE COF CASHEW C\\n\\nDOCS PINT ORGANIC\\n\\nHNY ALMOND BUTTER\\n-00 BAL\\n\\nNP 4.99\\nNP 4.99\\nNP 4.99\\nNP 4,99\\nNP 2.19\\nNP wi .99\\nNP 18.80\\nNP 3.39\\nNP 6.49\\nNP ,B.04\\nnp £8.99\\nNP \"14.49\\nNP 9.99\\n\\n101.33\\n\\nTAAAAHNAAAAAATAT\\n\\n»\\n\\x0c'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = psm_options(\"whole_foods-2.png\", options=\"--psm 4\")\n",
        "results"
      ],
      "metadata": {
        "id": "uTgPrmWVuJix",
        "outputId": "fa564337-7b4d-47d0-c8c1-19a76e51400f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'WHOLE\\nFOODS\\n[Mm AR K E T)\\n\\nWHOLE FOODS MARKET - WESTPORT,CT 06880\\n399 POST RD WEST ~ (203) 227-6858\\n\\n365 BACON LS NP 4.99\\n\\n365 BACON LS NP 4.99\\n\\n366 BACON LS NP 4.99\\n\\n365 BACON LS NP 4.99\\nBROTH CHIC NP 2.19\\n\\nFLOUR ALMOND NP wil .99\\n\\nCHKN BRST BNLSS SK NP 18.80\\nHEAVY CREAM NP 3.39\\n\\nBALSMC REDUCT NP 6.49\\n\\nBEEF GRND 85/1§ NP 5.04\\nJUICE COF CASHEW C NP 8.99\\nDOCS PINT ORGANIC NP °14.49\\nHNY ALMOND BUTTER NP 9.99\\nween TAX -00 BAL - 101.33\\n\\nF\\nF\\n\\x0c'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PSM 5"
      ],
      "metadata": {
        "id": "aWWfui-juefr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = psm_options(\"whole_foods-3.png\")\n",
        "results"
      ],
      "metadata": {
        "id": "HbvUd3U2uf98",
        "outputId": "2048b061-bb9e-44db-9f11-b5a9c0504bbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Se\\n\\nWHOLE\\nFOODS\\ncee eam\\n\\nWHOLE FOODS MARKET - WESTPORT, CT\\n399 POST RD WEST - (203) 227-6858\\n\\n365 BACON LS NP\\n366 BACON LS NP\\n365 BACON LS NP\\n365 BACON LS NP\\n\\nBROTH CHIC NP\\n\\n06880\\n\\n4.99\\n4.99\\n4.99\\n4.99\\n2.19\\n\\nFLOUR ALMOND NP oi1.99\\n\\nCHKN BRST BNLSS SK NP\\nHEAVY CREAM NP\\n\\nBALSMC REDUCT NP\\n\\nBEEF GRND 85/1§ NP\\n\\nJUICE COF CASHEW C NP\\n\\n’ DOCS PINT ORGANIC NP\\nHNY ALMOND BUTTER NP\\n\\nune TAX 00 BAL ~ 101.33\\n\\n18.80\\n\\n6.49\\n5.04\\n8.99\\n14.49\\n9.99\\n\\ni\\n\\x0c'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = psm_options(\"whole_foods-3.png\", options=\"--psm 5\")\n",
        "results"
      ],
      "metadata": {
        "id": "rz3jPw1UuuQO",
        "outputId": "949e30b7-9591-4cda-93f7-76e28bdf446f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Cex ae\\n\\nWHOLE FOODS MARKET - WESTPORT,CT 06880\\n\\n399 POST RD WEST - (203) 227-6858\\n* 365 BACON LS NP 4.99 F\\n* 365 BACON LS NP 4.99 F\\n* 365 BACON LS NP 4.99 F*\\n* 365 BACON LS NP 4.99 F\\n* BROTH CHIC NP 2.19 F\\n* FLOUR ALMOND NP i1.99 F\\n. CHKN BRST BNLSS SK NP 18.80 F\\n* HEAVY CREAM NP 3.39 F\\n* BALSMC REDUCT NP 6.49 F\\n* BEEF GRND 85/1§ NP 6.04 F\\n. JUICE COF CASHEW C NP fs 99 F\\na DOCS PINT ORGANIC NP °14.49 F\\n* HNY ALMOND BUTTER NP 9.99 F\\n\\nune TAX 00 BAL ~ 101.33\\n\\x0c'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PSM 6"
      ],
      "metadata": {
        "id": "4gSZaE4FvTmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = psm_options(\"sherlock_holmes.png\")\n",
        "print(results)"
      ],
      "metadata": {
        "id": "mkDTwhcYvUwT",
        "outputId": "8219a8ef-0ec5-49d8-8cba-267030df4b52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CHAPTER ONE\n",
            "\n",
            "wee\n",
            "Mr. Sherlock Holmes\n",
            "\n",
            " \n",
            "\n",
            "M r, Sherlock Holmes, who was usually very late in the\n",
            "\n",
            "sions when he\n",
            "\n",
            " \n",
            "\n",
            "ings, save upon those not infrequent oc\n",
            "was up all night, was seated at the breakfast\n",
            "the hearth-rug and picked up the stick which ou\n",
            "n the night before. It was\n",
            "\n",
            "~aded, of the sort which is known as a “Penang lawyer.\n",
            "\n",
            " \n",
            "\n",
            "ble. I stood upon\n",
            "visitor had left\n",
            "\n",
            "    \n",
            "\n",
            "  \n",
            "\n",
            "behind fine, thick piece of wood,\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "bulbous-h\n",
            "\n",
            " \n",
            "\n",
            "Just under the head was a broad silver band nearly an inch across.\n",
            "“To James Mortimer, M.R.C.S., from his friends of the C.C.H.,”\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "      \n",
            "\n",
            "    \n",
            "\n",
            " \n",
            "\n",
            "    \n",
            "\n",
            "was engraved upon it, with the date “1884.” It was just such\n",
            "stick as the old-fashioned family practitioner used to c: dig-\n",
            "nified, solid, and reassuring,\n",
            "\n",
            "“Well, Watson, what do you ike of i?”\n",
            "\n",
            "Holmes was sitting with his back to me, and I had given him no\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "sign of my occupation.\n",
            "“How did you know what I was doing? I believe you have eyes in\n",
            "the back of your head.”\n",
            "\n",
            "“T have, at least, a well-polished, silver-plated coffee-pot in front\n",
            "of me,” said he. “But, tell me, Watson, what do you make of our\n",
            "\n",
            "visitor's stick? Since we have been so unfortunate as to miss him.\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "and have no notion of his errand, this accidental souvenir be\n",
            "comes of importance\n",
            "mination of it.”\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\n",
            "Let me he:\n",
            "\n",
            " \n",
            "\n",
            "you reconstruct the man by\n",
            "\n",
            " \n",
            "\n",
            " \n",
            "\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = psm_options(\"sherlock_holmes.png\", options=\"--psm 6\")\n",
        "print(results)"
      ],
      "metadata": {
        "id": "HAJoQATAvWVv",
        "outputId": "581504c8-1b2e-4a41-9092-4dc8b06e4900",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CHAPTER ONE\n",
            "wee\n",
            "Mr. Sherlock Holmes\n",
            "M r, Sherlock Holmes, who was usually very late in the morn-\n",
            "ings, save upon those not infrequent occasions when he\n",
            "\n",
            "was up all night, was seated at the breakfast table. I stood upon\n",
            "the hearth-rug and picked up the stick which our visitor had left\n",
            "behind him the night before. It was a fine, thick piece of wood,\n",
            "bulbous-headed, of the sort which is known as a “Penang lawyer.”\n",
            "Just under the head was a broad silver band nearly an inch across.\n",
            "“To James Mortimer, M.R.C.S., from his friends of the C.C.H.,”\n",
            "was engraved upon it, with the date “1884.” It was just such a\n",
            "stick as the old-fashioned family practitioner used to carry—dig-\n",
            "nified, solid, and reassuring,\n",
            "\n",
            "“Well, Watson, what do you make of it?”\n",
            "\n",
            "Holmes was sitting with his back to me, and I had given him no\n",
            "sign of my occupation.\n",
            "\n",
            "“How did you know what I was doing? I believe you have eyes in\n",
            "the back of your head.”\n",
            "\n",
            "“T have, at least, a well-polished, silver-plated coffee-pot in front\n",
            "of me,” said he. “But, tell me, Watson, what do you make of our\n",
            "visitor's stick? Since we have been so unfortunate as to miss him.\n",
            "and have no notion of his errand, this accidental souvenir be-\n",
            "comes of importance. Let me hear you reconstruct the man by an\n",
            "examination of it.”\n",
            "\n",
            "6\n",
            "\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PSM 7"
      ],
      "metadata": {
        "id": "OSpTAob6xqUn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = psm_options(\"license_plate-1.png\")\n",
        "print(results)"
      ],
      "metadata": {
        "id": "iPqpcpLGxrig",
        "outputId": "b39baaee-6b47-495b-cc8a-772bdbc257fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MHO4DW8351\n",
            "\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = psm_options(\"license_plate-1.png\", options=\"--psm 7\")\n",
        "print(results)"
      ],
      "metadata": {
        "id": "fe9kq-7oxue-",
        "outputId": "1184ac07-1022-42df-821c-ae0d202d9475",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MHO4DW8351\n",
            "\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PSM 8"
      ],
      "metadata": {
        "id": "7nzTDed3yWdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = psm_options(\"designer.png\")\n",
        "print(results)"
      ],
      "metadata": {
        "id": "9JpANSGox3Ov",
        "outputId": "1e6767e4-ce4f-4541-ca9a-729db5fcf184",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = psm_options(\"designer.png\", options=\"--psm 8\")\n",
        "print(results)"
      ],
      "metadata": {
        "id": "WtwjIGLRyY5r",
        "outputId": "36c7f342-38c0-45a2-cee6-531737bca173",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "a\n",
            "\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PSM 11"
      ],
      "metadata": {
        "id": "otddpQS5zKmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = psm_options(\"website_menu.png\")\n",
        "print(results)"
      ],
      "metadata": {
        "id": "PrSxgXUjzL4T",
        "outputId": "65971202-6d63-45d7-88e6-4599891a5f76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How Do | Get Started?\n",
            "\n",
            "Deep Learning\n",
            "\n",
            "Face Applications\n",
            "\n",
            "Optical Character Recognition (OCR)\n",
            "Object Detection\n",
            "\n",
            "Object Tracking\n",
            "\n",
            "Instance Segmentation and Semantic\n",
            "\n",
            "Segmentation\n",
            "\n",
            "Embedded and loT Computer Vision\n",
            "Computer Vision on the Raspberry Pi\n",
            "Medical Computer Vision\n",
            "\n",
            "Working with Video\n",
            "\n",
            "Image Search Engines\n",
            "\n",
            "Interviews, Case Studies, and Success Stories\n",
            "\n",
            "My Books and Courses\n",
            "\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = psm_options(\"website_menu.png\", options=\"--psm 11\")\n",
        "print(results)"
      ],
      "metadata": {
        "id": "EEsvVavIzNzQ",
        "outputId": "fd16b0a7-50f8-486b-a274-228c873e5897",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How Do | Get Started?\n",
            "\n",
            "Deep Learning\n",
            "\n",
            "Face Applications\n",
            "\n",
            "Optical Character Recognition (OCR)\n",
            "\n",
            "bject Det n\n",
            "\n",
            "Object Tracking\n",
            "\n",
            "Instance Segmentation and Semantic\n",
            "\n",
            "Segmentation\n",
            "\n",
            "Embedded and loT Computer Vision\n",
            "\n",
            "Computer Vision on the Raspberry Pi\n",
            "\n",
            "Medical Computer Vision\n",
            "\n",
            "Working with Video\n",
            "\n",
            "Image Search Engines\n",
            "\n",
            "Interviews, Case Studies, and Success Stories\n",
            "\n",
            "My Books and Courses\n",
            "\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##PSM 12"
      ],
      "metadata": {
        "id": "EOq7a3Gi0drL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = psm_options(\"website_menu.png\", options=\"--osd 0 --psm 12\")\n",
        "print(results)"
      ],
      "metadata": {
        "id": "pWCxFh470UMK",
        "outputId": "964503ba-584b-4cb6-bda2-3309b2449c01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "How Do | Get Started?\n",
            "\n",
            "Deep Learning\n",
            "\n",
            "Face Applications\n",
            "\n",
            "Optical Character Recognition (OCR)\n",
            "Object Detection\n",
            "\n",
            "Object Tracking\n",
            "\n",
            "Instance Segmentation and Semantic\n",
            "\n",
            "Segmentation\n",
            "\n",
            "Embedded and loT Computer Vision\n",
            "Computer Vision on the Raspberry Pi\n",
            "Medical Computer Vision\n",
            "\n",
            "Working with Video\n",
            "\n",
            "Image Search Engines\n",
            "\n",
            "Interviews, Case Studies, and Success Stories\n",
            "\n",
            "My Books and Courses\n",
            "\f\n"
          ]
        }
      ]
    }
  ]
}