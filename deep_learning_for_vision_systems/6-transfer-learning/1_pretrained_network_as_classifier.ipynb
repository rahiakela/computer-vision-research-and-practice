{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-pretrained-network-as-classifier.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPpxgfz9v24Tdh9GR1ZQ+C5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/deep_learning_for_vision_systems/blob/master/6-transfer-learning/1_pretrained_network_as_classifier.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMpv3TSD3uRH"
      },
      "source": [
        "# Transfer learning approaches"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMG5KpwN35r_"
      },
      "source": [
        "There are three major transfer learning approaches as follows:\n",
        "\n",
        "1. Pretrained network as a classifier\n",
        "2. Pretrained network as feature extractor\n",
        "3. Fine tuning\n",
        "\n",
        "Each approach can be effective and save significant time in developing and training a deep convolutional neural network model. It may not be clear as to which usage of the pre-trained model may yield the best results on your new computer vision task, therefore some experimentation may be required."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YySxJqGD4IxX"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PgdfWvDu4MxF"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAFdzpUWKPF9",
        "outputId": "eb769703-2af7-4945-8936-14b2d69029e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%shell\n",
        "\n",
        "wget -q https://github.com/rahiakela/deep_learning_for_vision_systems/raw/master/6-transfer-learning/dog.jpg\n",
        "wget -q https://github.com/rahiakela/deep_learning_for_vision_systems/raw/master/6-transfer-learning/cat.jpg"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1RG6oBhc4N8T"
      },
      "source": [
        "## Pretrained network as a classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dGNlsjA4Ovi"
      },
      "source": [
        "**The pre-trained model is used directly to classify new images with no changes applied to it and no extra training. All we do here is download the network architecture and its pretrained weights. Then run the predictions directly on our new data.** \n",
        "\n",
        "In this case, we are saying that the domain of our new problem is very similar to the one that the pretrained network was trained on and it is ready to just be “deployed”. So no training is done here.\n",
        "\n",
        "In the dog breed example, we could have used VGG16 network that was trained on ImageNet dataset directly to run predictions. Because ImageNet already contains a lot dog breeds images so the significant portion of the representational power of the pretrained network may be devoted to features that are specific to differentiating between dog breeds.\n",
        "\n",
        "**Using a pretrained network as a classifier doesn’t really involve any layers freezing or extra model training. Instead, it is just taking a network that was trained on your similar problem and deploying it directly to your task.**\n",
        "\n",
        "Let’s see how to use a pretrained network as a classifier. In this example, we will use a VGG16 network that was pretrained on the ImageNet dataset to classify the image of the German Shepherd dog.\n",
        "\n",
        "<img src='https://raw.githubusercontent.com/moelgendy/deep_learning_for_vision_systems/master/chapter_06/dog.jpg?raw=1' width='800'/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iz2bkMrO6OAX"
      },
      "source": [
        "Download the pretrained model of VGG16 and its ImageNet weights. We will set\n",
        "include_top to True because we want to use the entire network as a classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnFrq1oE6AMY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4703c560-5b74-4640-889b-8679fbd18419"
      },
      "source": [
        "# load the VGG16 model\n",
        "model = VGG16(weights='imagenet', include_top=True, input_shape=(224, 224, 3))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
            "553467904/553467096 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9RMN6Ax6hgx"
      },
      "source": [
        "Load and preprocess the input image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LX_MPeVM6iIP"
      },
      "source": [
        "# load an image from file\n",
        "image = load_img('dog.jpg', target_size=(224, 224))\n",
        "\n",
        "# convert the image pixels to a numpy array\n",
        "image = img_to_array(image)\n",
        "\n",
        "# reshape data for the model\n",
        "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "\n",
        "# prepare the image for the VGG model\n",
        "image = preprocess_input(image)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykaSCoul7hX7"
      },
      "source": [
        "Now our input image is ready for us to run the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xM1gORw7h7N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbda7ff4-f7cc-4f5d-ac07-a4bdf27bd2fa"
      },
      "source": [
        "# predict the probability across all output classes\n",
        "yhat = model.predict(image)\n",
        "\n",
        "# convert the probabilities to class labels\n",
        "label = decode_predictions(yhat)\n",
        "\n",
        "# retrieve the most likely result with the highest probability\n",
        "label = label[0][0]\n",
        "\n",
        "# print the classification\n",
        "print('%s (%.2f%%)' % (label[1], label[2] * 100))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
            "40960/35363 [==================================] - 0s 0us/step\n",
            "German_shepherd (99.72%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KL40vydf8ZEd"
      },
      "source": [
        "You can see that the model was already trained to predict the correct dog breed with a high confidence score (99.72%). This is because the ImageNet dataset has more than 20,000 labeled dog images and classified into 120 classes.\n",
        "\n",
        "Let's test it with a cat image."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPoKD98m8Nvs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dca568c0-71ca-4510-be1e-5d010c399459"
      },
      "source": [
        "# load an image from file\n",
        "image = load_img('cat.jpg', target_size=(224, 224))\n",
        "\n",
        "# convert the image pixels to a numpy array\n",
        "image = img_to_array(image)\n",
        "\n",
        "# reshape data for the model\n",
        "image = image.reshape((1, image.shape[0], image.shape[1], image.shape[2]))\n",
        "\n",
        "# prepare the image for the VGG model\n",
        "image = preprocess_input(image)\n",
        "\n",
        "# predict the probability across all output classes\n",
        "yhat = model.predict(image)\n",
        "\n",
        "# convert the probabilities to class labels\n",
        "label = decode_predictions(yhat)\n",
        "\n",
        "# retrieve the most likely result with the highest probability\n",
        "label = label[0][0]\n",
        "\n",
        "# print the classification\n",
        "print('%s (%.2f%%)' % (label[1], label[2] * 100))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Egyptian_cat (65.18%)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}