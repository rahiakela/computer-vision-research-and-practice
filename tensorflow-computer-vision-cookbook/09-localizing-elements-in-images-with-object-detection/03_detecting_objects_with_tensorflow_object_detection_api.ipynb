{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "03-detecting-objects-with-tensorflow-object-detection-api.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNjKKj92x1gRAJbUubgDy+H",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/tensorflow-computer-vision-cookbook/blob/main/09-localizing-elements-in-images-with-object-detection/03_detecting_objects_with_tensorflow_object_detection_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AwjrPlYUUAR0"
      },
      "source": [
        "##Detecting objects with TensorFlow's Object Detection API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLpvsvKBWcdq"
      },
      "source": [
        "It's no secret that modern object detectors rank among the most complex and challenging architectures to implement and get it right! However, that doesn't mean we can't take advantage of the most recent advancements in this domain in order to train object detectors on our own datasets. How?. Enter TensorFlow's Object Detection API!\n",
        "\n",
        "In this recipe, we'll install this API, prepare a custom dataset for training, tweak a couple of configuration files, and use the resulting model to localize objects on test images. This recipe is a bit different from the ones you've worked on so far, because we'll be switching back and forth between Python and the command line."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr83uKG6Wr-V"
      },
      "source": [
        "##Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YBbgMlyW6sX"
      },
      "source": [
        "Let's begin with the most important one: the TensorFlow Object Detection API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EdUi0IBKWyp_",
        "outputId": "c7966453-4061-41aa-e6b5-f89369f6b79d"
      },
      "source": [
        "!git clone --depth 1 https://github.com/tensorflow/models.git"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 2802, done.\u001b[K\n",
            "remote: Counting objects: 100% (2802/2802), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2333/2333), done.\u001b[K\n",
            "remote: Total 2802 (delta 717), reused 1296 (delta 433), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2802/2802), 32.79 MiB | 29.40 MiB/s, done.\n",
            "Resolving deltas: 100% (717/717), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wya2wXczYL8E"
      },
      "source": [
        "Next, install the TensorFlow Object Detection API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4KkegQQcWtMS"
      },
      "source": [
        "!cd models\n",
        "!sudo apt install -y protobuf-compiler\n",
        "!cd models/research\n",
        "!protoc models/research/object_detection/protos/*.proto --python_out=.\n",
        "!cp models/research/object_detection/packages/tf2/setup.py .\n",
        "!python -m pip install -q ."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T7MnAZkRYQKq"
      },
      "source": [
        "Or alternatavly, we can install object-detection-api.\n",
        "\n",
        "https://stackoverflow.com/questions/50113683/modulenotfounderror-no-module-named-object-detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUuzwWsqYQxW"
      },
      "source": [
        "!pip install tensorflow-object-detection-api"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WJ_dF9j0Z_l0"
      },
      "source": [
        "Let's download Fruit Images for Object Detection dataset from [Kaggle](https://www.kaggle.com/mbkinaci/fruit-images-for-object-detection#)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI1lHbZHaKpN"
      },
      "source": [
        "from google.colab import files\n",
        "files.upload() # upload kaggle.json file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ueCTuNsVaMvJ",
        "outputId": "fc11c4db-7200-4a7d-eef6-6c673b7ede43"
      },
      "source": [
        "%%shell\n",
        "\n",
        "mkdir -p ~/.kaggle\n",
        "mv kaggle.json ~/.kaggle/\n",
        "ls ~/.kaggle\n",
        "chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "# download word embeddings from kaggle\n",
        "kaggle datasets download -d mbkinaci/fruit-images-for-object-detection\n",
        "unzip -qq fruit-images-for-object-detection.zip\n",
        "rm -rf fruit-images-for-object-detection.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n",
            "Downloading fruit-images-for-object-detection.zip to /content\n",
            " 32% 9.00M/28.4M [00:00<00:00, 37.3MB/s]\n",
            "100% 28.4M/28.4M [00:00<00:00, 81.4MB/s]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9_bi0od5WtZO"
      },
      "source": [
        "import glob\n",
        "import io\n",
        "import os\n",
        "from collections import namedtuple\n",
        "from xml.etree import ElementTree as tree\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow.compat.v1 as tf\n",
        "from PIL import Image\n",
        "from object_detection.utils import dataset_util"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVhiU88Ra3Fa"
      },
      "source": [
        "## Define some helper function"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUM7C51Ga61o"
      },
      "source": [
        "We'll work with two files in this recipe: \n",
        "\n",
        "- the first one is used to prepare the data \n",
        "- the second one is used to make inferences with the object detector\n",
        "\n",
        "Let's define the encode_class() function, which maps the text labels to their integer counterparts."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZFoXzw30NAO4"
      },
      "source": [
        "def encode_class(row_label):\n",
        "  class_mapping = {\"apple\": 1, \"orange\": 2, \"banana\": 3}\n",
        "  return class_mapping.get(row_label, None)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X1t71vuAO0YD"
      },
      "source": [
        "Let's define a function to split a dataframe of labels into groups."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZY2raS5NYB4"
      },
      "source": [
        "def split(df, group):\n",
        "  data = namedtuple(\"data\", [\"filename\", \"object\"])\n",
        "  groups = df.groupby(group)\n",
        "\n",
        "  return [data(filename, groups.get_group(x)) for filename, x in zip(groups.group.keys(), groups.group)]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LR8ijnofPEPm"
      },
      "source": [
        "The TensorFlow Object Detection API works with a data structure known as\n",
        "`tf.train.Example`. \n",
        "\n",
        "The next function takes the path to an image and its label\n",
        "(which is the set of bounding boxes and the ground-truth classes of all objects\n",
        "contained in it) and creates the corresponding `tf.train.Example`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H50dKDGTOvlu"
      },
      "source": [
        "def create_tf_example(group, path):\n",
        "  # First, load the image and its properties\n",
        "  groups_path = os.path.join(path, f\"{group.filename}\")\n",
        "  with tf.gfile.GFile(groups_path, \"rb\") as f:\n",
        "    encoded_jpg = f.read()\n",
        "\n",
        "  image = Image.open(io.BytesIO(encoded_jpg))\n",
        "  width, height = image.size\n",
        "\n",
        "  filename = group.filename.encode(\"utf8\")\n",
        "  image_format = b\"jpg\"\n",
        "\n",
        "  # Now, store the dimensions of the bounding boxes, along with the classes of each object contained in the image\n",
        "  xmins = []\n",
        "  xmaxs = []\n",
        "  ymins = []\n",
        "  ymaxs = []\n",
        "  classes_text = []\n",
        "  classes = []\n",
        "\n",
        "  for index, row in group.object.iterrows():\n",
        "    xmins.append(row['xmin'] / width)\n",
        "    xmaxs.append(row['xmax'] / width)\n",
        "    ymins.append(row['ymin'] / height)\n",
        "    ymaxs.append(row['ymax'] / height)\n",
        "    classes_text.append(row['class'].encode('utf8'))\n",
        "    classes.append(encode_class(row['class']))\n",
        "\n",
        "  # Create a tf.train.Features object that will contain relevant information about the image and its objects\n",
        "  features = tf.train.Features(feature={\n",
        "      'image/height': dataset_util.int64_feature(height),\n",
        "      'image/width': dataset_util.int64_feature(width),\n",
        "      'image/filename': dataset_util.bytes_feature(filename),\n",
        "      'image/source_id': dataset_util.bytes_feature(filename),\n",
        "      'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "      'image/format': dataset_util.bytes_feature(image_format),\n",
        "      'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "      'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "      'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "      'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "      'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "      'image/object/class/label': dataset_util.int64_list_feature(classes)\n",
        "  })\n",
        "\n",
        "  return tf.train.Features(features=features)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPE1kpj1S0B-"
      },
      "source": [
        "Now, define a function to transform an Extensible Markup Language (XML) file—\n",
        "with information about the bounding boxes in an image—to an equivalent one in\n",
        "Comma-Separated Values (CSV) format."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0ma3BXbSMjF"
      },
      "source": [
        "def bboxes_to_csv(path):\n",
        "  xml_list = []\n",
        "\n",
        "  bboxes_pattern = os.path.sep.join([path, '*.xml'])\n",
        "  for xml_file in glob.glob(bboxes_pattern):\n",
        "    t = tree.parse(xml_file)\n",
        "    root = t.getroot()\n",
        "\n",
        "    for member in root.findall('object'):\n",
        "        value = (root.find('filename').text,\n",
        "                  int(root.find('size')[0].text),\n",
        "                  int(root.find('size')[1].text),\n",
        "                  member[0].text,\n",
        "                  int(member[4][0].text),\n",
        "                  int(member[4][1].text),\n",
        "                  int(member[4][2].text),\n",
        "                  int(member[4][3].text))\n",
        "        xml_list.append(value)\n",
        "\n",
        "  column_names = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "  df = pd.DataFrame(xml_list, columns=column_names)\n",
        "  \n",
        "  return df"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GV1YyZp3TitU"
      },
      "source": [
        "Now, iterate over the test and train subsets in the fruits folder, converting the labels from CSV to XML."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NbudgriITTnu",
        "outputId": "7559b74d-f275-4164-ebc9-0a4dc48728f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "source": [
        "base = \"fruits\"\n",
        "for subset in [\"test\", \"train\"]:\n",
        "  folder = os.path.sep.join([f\"{subset}_zip\", subset])\n",
        "  labels_path = os.path.sep.join([f\"{subset}_labels.csv\"])\n",
        "\n",
        "  bboxes_df = bboxes_to_csv(folder)\n",
        "  bboxes_df.to_csv(labels_path, index=None)\n",
        "\n",
        "  # Then, use the same labels to produce the tf.train.Examples corresponding to the current subset of data being processed:\n",
        "  writer = (tf.python_io.TFRecordWriter(f\"resources/{subset}.record\"))\n",
        "  examples = pd.read_csv(f\"fruits/{subset}_labels.csv\")\n",
        "  grouped = split(examples, \"filename\")\n",
        "\n",
        "  path = os.path.join(f\"fruits/{subset}_zip/{subset}\")\n",
        "  for group in grouped:\n",
        "    tf_example = create_tf_example(group, path)\n",
        "    writer.write(tf_example.SerializeToString())\n",
        "  writer.close()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-278a43a58fe7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;31m# Then, use the same labels to produce the tf.train.Examples corresponding to the current subset of data being processed:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m   \u001b[0mwriter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_io\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTFRecordWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"resources/{subset}.record\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m   \u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"fruits/{subset}_labels.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0mgrouped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"filename\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/lib/io/tf_record.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, path, options)\u001b[0m\n\u001b[1;32m    297\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m     super(TFRecordWriter, self).__init__(\n\u001b[0;32m--> 299\u001b[0;31m         compat.as_bytes(path), options._as_record_writer_options())\n\u001b[0m\u001b[1;32m    300\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotFoundError\u001b[0m: resources/test.record; No such file or directory"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3x8sbSJJVNIP"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}